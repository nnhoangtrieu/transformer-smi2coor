{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully extracted\n",
      "----------------------------------------\n",
      "Size: 4255\n",
      "Longest SMILES: 36\n",
      "Longest Coordinate: 22\n",
      "----------------------------------------\n",
      "\n",
      "Below is one example for each variable: \n",
      "\n",
      "\n",
      "smi_dic (SMILES Dictionary):\n",
      "\t {'x': 0, 'E': 1, 'C': 2, 'n': 3, '1': 4, 'c': 5, '(': 6, ')': 7, 'B': 8, 'O': 9, 'F': 10, 'S': 11, '=': 12, 'o': 13, 'N': 14, '#': 15, '/': 16, 'l': 17, '\\\\': 18, '2': 19, '[': 20, 'H': 21, ']': 22, '+': 23, '-': 24, 's': 25, '.': 26, 'K': 27, '3': 28, 'r': 29, 'P': 30, 'a': 31}\n",
      "\n",
      "\n",
      "smi_list (SMILES List):\n",
      "\t Cn1ncc(c1)B1OC(C(O1)(C)C)(C)CE\n",
      "\n",
      "\n",
      "smint_list (SMILES Integer List):\n",
      "\t [2, 3, 4, 3, 5, 5, 6, 5, 4, 7, 8, 4, 9, 2, 6, 2, 6, 9, 4, 7, 6, 2, 7, 2, 7, 6, 2, 7, 2, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "coor_list (Coordinate List):\n",
      "\t [[4.8285, -1.004, 0.2024], [3.5776, -0.2572, 0.0479], [3.4435, 1.1346, 0.1047], [2.1893, 1.445, -0.0747], [1.4645, 0.2475, -0.2554], [2.3676, -0.7919, -0.1777], [-0.0805, 0.1225, -0.5047], [-1.0404, 1.1849, -0.5963], [-2.2048, 0.6858, 0.0949], [-2.0701, -0.8493, 0.0305], [-0.8409, -1.0789, -0.697], [-1.9777, -1.4359, 1.4405], [-3.2539, -1.4571, -0.7246], [-2.2055, 1.1603, 1.5494], [-3.4816, 1.1392, -0.6157]]\n",
      "\n",
      "\n",
      "np_coor_list (Normalized + Padded Coordinate List):\n",
      "\t tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [-1.2500,  0.7500, -0.1500],\n",
      "        [-1.3900,  2.1400, -0.1000],\n",
      "        [-2.6400,  2.4500, -0.2800],\n",
      "        [-3.3600,  1.2500, -0.4600],\n",
      "        [-2.4600,  0.2100, -0.3800],\n",
      "        [-4.9100,  1.1300, -0.7100],\n",
      "        [-5.8700,  2.1900, -0.8000],\n",
      "        [-7.0300,  1.6900, -0.1100],\n",
      "        [-6.9000,  0.1500, -0.1700],\n",
      "        [-5.6700, -0.0700, -0.9000],\n",
      "        [-6.8100, -0.4300,  1.2400],\n",
      "        [-8.0800, -0.4500, -0.9300],\n",
      "        [-7.0300,  2.1600,  1.3500],\n",
      "        [-8.3100,  2.1400, -0.8200],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "from utils.data_preprocess import train_loader, test_loader, smi_list, smint_list, smi_dic, coor_list, np_coor_list, longest_coor, longest_smi, device\n",
    "from utils.helper import visualize, timeSince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim_model):\n",
    "        super(Attention, self).__init__()\n",
    "        self.Wa = nn.Linear(dim_model, dim_model)\n",
    "        self.Ua = nn.Linear(dim_model, dim_model)\n",
    "        self.Va = nn.Linear(dim_model, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights # context : attention, weights : distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "  def __init__(self, input_size, dim_model, dropout_p = 0.1) :\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.self_attn = Attention(dim_model)\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, dim_model) # input_size : num words in input language dictionary - dim_model : dimension that we want to map to\n",
    "\n",
    "    self.gru = nn.GRU(dim_model, dim_model, batch_first = True)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    self.out = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "  def forward(self, input) :\n",
    "    embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "    attn, self_attn = self.self_attn(embedded, embedded)\n",
    "    # print(f'self_attn: {self_attn.shape}')\n",
    "    all_states, last_state = self.gru(embedded + attn)\n",
    "\n",
    "    return all_states, last_state, self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, dim_model, longest_coordinate, output_size = 3) :\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.attention = Attention(dim_model)\n",
    "    self.gru = nn.GRU(3 + dim_model, dim_model, batch_first = True)\n",
    "    self.out = nn.Linear(dim_model, output_size)\n",
    "    self.longest_coor = longest_coordinate\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "  def forward(self, e_all, e_last, target_tensor = None) :\n",
    "    batch_size = e_all.size(0)\n",
    "\n",
    "    d_input = torch.zeros(batch_size, 1, 3).to(device)\n",
    "\n",
    "    d_hidden = e_last\n",
    "\n",
    "    d_outputs = []\n",
    "    attentions = []\n",
    "\n",
    "    for i in range(self.longest_coor) :\n",
    "      d_output, d_hidden, a_weights = self.forward_step(d_input, d_hidden, e_all)\n",
    "\n",
    "      d_outputs.append(d_output)\n",
    "      attentions.append(a_weights)\n",
    "\n",
    "      if target_tensor is not None :\n",
    "        d_input = target_tensor[:, i, :].unsqueeze(1)\n",
    "      else :\n",
    "        d_input = d_output\n",
    "\n",
    "\n",
    "    d_outputs = torch.cat(d_outputs, dim = 1)\n",
    "    attentions = torch.cat(attentions, dim = 1)\n",
    "\n",
    "    return d_outputs, attentions\n",
    "\n",
    "  def forward_step(self, d_input, d_hidden, e_all) : # d_hidden : last encoder state\n",
    "    query = d_hidden.permute(1,0,2)\n",
    "\n",
    "    d_input = self.dropout(d_input) \n",
    "\n",
    "    attn, cross_attn = self.attention(query, e_all)\n",
    "    \n",
    "    input_gru = torch.cat((d_input, attn), dim = 2)\n",
    "\n",
    "    output, d_hidden = self.gru(input_gru, d_hidden)\n",
    "\n",
    "    output = self.out(output) \n",
    "    return output, d_hidden, cross_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "r = random.randint(1, len(smi_list))\n",
    "\n",
    "def train_epoch(train_loader,test_loader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, tf):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad(), decoder_optimizer.zero_grad()\n",
    "        \n",
    "        e_all, e_last, self_attn = encoder(input)\n",
    "\n",
    "        # Teacher Forcing\n",
    "        if tf :\n",
    "          prediction, cross_attn = decoder(e_all, e_last, target)\n",
    "        else :\n",
    "          prediction, cross_attn = decoder(e_all, e_last)\n",
    "        print(f'self_attn: {self_attn.shape}')\n",
    "        print(f'cross_attn: {cross_attn.shape}')\n",
    "\n",
    "        loss = criterion(prediction, target)\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step(), decoder_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    encoder.eval(), decoder.eval()\n",
    "    \n",
    "\n",
    "\n",
    "    with torch.no_grad() :\n",
    "      for input, target in test_loader :\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        \n",
    "        e_all, e_last, self_attn = encoder(input)\n",
    "        prediction, cross_attn = decoder(e_all, e_last)\n",
    "\n",
    "        test_loss = criterion(prediction, target)\n",
    "        total_test_loss += test_loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader), total_test_loss / len(test_loader)\n",
    "\n",
    "\n",
    "def train(train_loader, test_loader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=1, visual_path= \"\", tf_rate = 1):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss_total = 0  \n",
    "    test_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    tf = True\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      if epoch > (tf_rate * n_epochs) :\n",
    "        tf = False\n",
    "      encoder.train()\n",
    "      decoder.train()\n",
    "\n",
    "      train_loss, test_loss = train_epoch(train_loader, test_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, tf)\n",
    "      train_loss_total += train_loss\n",
    "      test_loss_total += test_loss\n",
    "\n",
    "      # for i in range(5) :\n",
    "      #    visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"cross\", path=f\"{visual_path}\", name=f\"R{i}-CROSS-E{epoch}\")\n",
    "      #    visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"self\", path=f\"{visual_path}\", name=f\"R{i}-SELF-E{epoch}\")\n",
    "\n",
    "      if epoch % print_every == 0:\n",
    "          train_loss_avg = train_loss_total / print_every\n",
    "          test_loss_avg = test_loss_total / print_every\n",
    "          train_loss_total = 0\n",
    "          test_loss_total = 0\n",
    "          print('%s (%d %d%%) /// Train loss: %.4f - Test loss: %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                      epoch, epoch / n_epochs * 100, train_loss_avg, test_loss_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_size=len(smi_dic),\n",
    "                  dim_model=256,\n",
    "                  dropout_p=0.1)\n",
    "\n",
    "decoder = Decoder(dim_model=256,\n",
    "                  longest_coordinate=longest_coor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n",
      "self_attn: torch.Size([16, 1, 36])\n",
      "cross_attn: torch.Size([16, 22, 36])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtf_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvisual_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 70\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, test_loader, encoder, decoder, n_epochs, learning_rate, print_every, visual_path, tf_rate)\u001b[0m\n\u001b[0;32m     67\u001b[0m encoder\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     68\u001b[0m decoder\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 70\u001b[0m train_loss, test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m train_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\n\u001b[0;32m     72\u001b[0m test_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m test_loss\n",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(train_loader, test_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, tf)\u001b[0m\n\u001b[0;32m     19\u001b[0m   prediction, cross_attn \u001b[38;5;241m=\u001b[39m decoder(e_all, e_last, target)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m---> 21\u001b[0m   prediction, cross_attn \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43me_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_attn: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mself_attn\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross_attn: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcross_attn\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, e_all, e_last, target_tensor)\u001b[0m\n\u001b[0;32m     19\u001b[0m attentions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlongest_coor) :\n\u001b[1;32m---> 22\u001b[0m   d_output, d_hidden, a_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m   d_outputs\u001b[38;5;241m.\u001b[39mappend(d_output)\n\u001b[0;32m     25\u001b[0m   attentions\u001b[38;5;241m.\u001b[39mappend(a_weights)\n",
      "Cell \u001b[1;32mIn[13], line 43\u001b[0m, in \u001b[0;36mDecoder.forward_step\u001b[1;34m(self, d_input, d_hidden, e_all)\u001b[0m\n\u001b[0;32m     39\u001b[0m query \u001b[38;5;241m=\u001b[39m d_hidden\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     41\u001b[0m d_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(d_input) \n\u001b[1;32m---> 43\u001b[0m attn, cross_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m input_gru \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((d_input, attn), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     47\u001b[0m output, d_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(input_gru, d_hidden)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, query, keys)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, keys):\n\u001b[1;32m----> 9\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mVa(torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWa(query) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     10\u001b[0m     scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m     weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_loader, test_loader, encoder, decoder,\n",
    "      n_epochs=100,\n",
    "      learning_rate=0.001,\n",
    "      tf_rate = 0.0,\n",
    "      visual_path=\"attention image\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
