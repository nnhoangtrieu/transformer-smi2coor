{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully extracted\n",
      "----------------------------------------\n",
      "Size: 4255\n",
      "Longest SMILES: 36\n",
      "Longest Coordinate: 22\n",
      "----------------------------------------\n",
      "smi_list (SMILES List):\n",
      "\t Cn1ncc(c1)B1OC(C(O1)(C)C)(C)CE\n",
      "smint_list (SMILES Integer List):\n",
      "\t [2, 3, 4, 3, 5, 5, 6, 5, 4, 7, 8, 4, 9, 2, 6, 2, 6, 9, 4, 7, 6, 2, 7, 2, 7, 6, 2, 7, 2, 1, 0, 0, 0, 0, 0, 0]\n",
      "coor_list (Coordinate List):\n",
      "\t [[4.8285, -1.004, 0.2024], [3.5776, -0.2572, 0.0479], [3.4435, 1.1346, 0.1047], [2.1893, 1.445, -0.0747], [1.4645, 0.2475, -0.2554], [2.3676, -0.7919, -0.1777], [-0.0805, 0.1225, -0.5047], [-1.0404, 1.1849, -0.5963], [-2.2048, 0.6858, 0.0949], [-2.0701, -0.8493, 0.0305], [-0.8409, -1.0789, -0.697], [-1.9777, -1.4359, 1.4405], [-3.2539, -1.4571, -0.7246], [-2.2055, 1.1603, 1.5494], [-3.4816, 1.1392, -0.6157]]\n",
      "np_coor_list (Normalized + Padded Coordinate List):\n",
      "\t tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [-1.2500,  0.7500, -0.1500],\n",
      "        [-1.3900,  2.1400, -0.1000],\n",
      "        [-2.6400,  2.4500, -0.2800],\n",
      "        [-3.3600,  1.2500, -0.4600],\n",
      "        [-2.4600,  0.2100, -0.3800],\n",
      "        [-4.9100,  1.1300, -0.7100],\n",
      "        [-5.8700,  2.1900, -0.8000],\n",
      "        [-7.0300,  1.6900, -0.1100],\n",
      "        [-6.9000,  0.1500, -0.1700],\n",
      "        [-5.6700, -0.0700, -0.9000],\n",
      "        [-6.8100, -0.4300,  1.2400],\n",
      "        [-8.0800, -0.4500, -0.9300],\n",
      "        [-7.0300,  2.1600,  1.3500],\n",
      "        [-8.3100,  2.1400, -0.8200],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "from utils.data_preprocess import train_loader, test_loader, smi_list, smint_list, smi_dic, coor_list, np_coor_list, longest_coor, longest_smi, device\n",
    "from utils.helper import visualize, timeSince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head) :\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.dim_model = dim_model\n",
    "        self.num_head = num_head\n",
    "        self.dim_head = dim_model // num_head\n",
    "\n",
    "        self.Q = nn.Linear(dim_model, dim_model)\n",
    "        self.K = nn.Linear(dim_model, dim_model)\n",
    "        self.V = nn.Linear(dim_model, dim_model)\n",
    "        \n",
    "        self.out = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "    def forward(self, Q, K, V) :\n",
    "        B = Q.size(0) # Shape Q, K, V: (B, longest_smi, dim_model)\n",
    "\n",
    "        Q, K, V = self.Q(Q), self.K(K), self.V(V)\n",
    "\n",
    "        len_Q, len_K, len_V = Q.size(1), K.size(1), V.size(1)\n",
    "\n",
    "        Q = Q.reshape(B, self.num_head, len_Q, self.dim_head)\n",
    "        K = K.reshape(B, self.num_head, len_K, self.dim_head)\n",
    "        V = V.reshape(B, self.num_head, len_V, self.dim_head)\n",
    "        \n",
    "        K_T = K.transpose(2,3).contiguous()\n",
    "\n",
    "        attn_score = Q @ K_T\n",
    "\n",
    "        attn_score = attn_score / (self.dim_head ** 1/2)\n",
    "\n",
    "        attn_distribution = torch.softmax(attn_score, dim = -1)\n",
    "\n",
    "        attn = attn_distribution @ V\n",
    "\n",
    "        attn = attn.reshape(B, len_Q, self.num_head * self.dim_head)\n",
    "        \n",
    "        attn = self.out(attn)\n",
    "\n",
    "        return attn, attn_distribution\n",
    "\n",
    "class LSTM(nn.Module) :\n",
    "    def __init__(self, dim_model, longest_coor, num_head = 1, output_size = 3) :\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.longest_coor = longest_coor\n",
    "\n",
    "        self.cross_attn = SelfAttention(dim_model, num_head)\n",
    "\n",
    "        self.lstm = nn.LSTM(3 + dim_model, dim_model, batch_first=True)\n",
    "\n",
    "        self.out = nn.Linear(dim_model, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, e_all, e_last, target = None) :\n",
    "        B = e_all.size(0)\n",
    "\n",
    "        d_input = torch.zeros(B, 1, 3).to(device)\n",
    "\n",
    "        d_hidden = e_last\n",
    "\n",
    "        d_outputs, cross_attn = [], []\n",
    "\n",
    "        for i in range(self.longest_coor) :\n",
    "            d_output, d_hidden, step_attn = self.forward_step(d_input, d_hidden, e_all)\n",
    "\n",
    "            d_outputs.append(d_output), cross_attn.append(step_attn)\n",
    "\n",
    "            if target is not None :\n",
    "                d_input = target[:, i, :].unsqueeze(1)\n",
    "            else :\n",
    "                d_input = d_output\n",
    "\n",
    "        d_outputs = torch.cat(d_outputs, dim = 1)\n",
    "\n",
    "        cross_attn = torch.cat(cross_attn, dim = 2)\n",
    "        \n",
    "        return d_outputs, d_hidden, cross_attn\n",
    "\n",
    "\n",
    "    def forward_step(self, d_input, d_hidden, e_all) :\n",
    "        Q = d_hidden.permute(1,0,2)\n",
    "\n",
    "        d_input = self.dropout(d_input)\n",
    "\n",
    "        attn, attn_distribution = self.cross_attn(Q, e_all, e_all)\n",
    "\n",
    "        input_lstm = torch.cat((attn, d_input), dim = 2)\n",
    "\n",
    "        output, _ = self.lstm(input_lstm) # Recheck about 2nd param\n",
    "\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, d_hidden, attn_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head, fe, dropout) :\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attn = SelfAttention(dim_model,num_head)\n",
    "        self.norm1 = nn.LayerNorm(dim_model)\n",
    "        self.norm2 = nn.LayerNorm(dim_model)\n",
    "        self.lstm = nn.LSTM(input_size=dim_model, hidden_size=dim_model, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(dim_model, fe * dim_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fe * dim_model, dim_model)\n",
    "        )\n",
    "    def forward(self, Q, K, V) :\n",
    "\n",
    "        all_state, (last_state, _) = self.lstm(Q)\n",
    "\n",
    "        attn, attn_distribution = self.self_attn(all_state, all_state, all_state)\n",
    "\n",
    "        # out = self.dropout(attn + all_state)\n",
    "\n",
    "        x = self.dropout(self.norm1(attn + all_state))\n",
    "\n",
    "        forward = self.feed_forward(x)\n",
    "\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "\n",
    "        return out, attn_distribution, last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "    def __init__(self, dim_model, num_block, num_head,\n",
    "                 len_dic, fe = 1, dropout = 0.1) :\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.dim_model = dim_model\n",
    "        self.embed = nn.Embedding(len_dic, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            EncoderBlock(dim_model, num_head, fe, dropout) for _ in range(num_block)\n",
    "        )\n",
    "\n",
    "    def forward(self, x) :\n",
    "        out = self.dropout(self.embed(x))\n",
    "\n",
    "        for block in self.encoder_blocks : \n",
    "            out, self_attn, last_state = block(out, out, out) \n",
    "        return out, last_state, self_attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head, longest_coor, fe, dropout) :\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.lstm = LSTM(dim_model, longest_coor, num_head)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim_model)\n",
    "        self.norm2 = nn.LayerNorm(dim_model)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(dim_model, fe * dim_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fe * dim_model, 3)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, e_all, e_last, target = None) :\n",
    "        output, _, cross_attn = self.lstm(e_all, e_last, target)\n",
    "        \n",
    "        x = self.dropout(self.norm1(output))\n",
    "\n",
    "        forward = self.feed_forward(x)\n",
    "\n",
    "        output = self.dropout(self.norm2(forward + x))\n",
    "\n",
    "        return output, cross_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, dim_model,num_block, num_head, longest_coor, fe = 1, dropout = 0.1) :\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "            [DecoderBlock(dim_model, num_head,longest_coor, fe, dropout) for _ in range(num_block)]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, e_all, e_last, target = None) :\n",
    "        for block in self.decoder_blocks :\n",
    "            target, cross_attn = block(e_all, e_last, target)\n",
    "        \n",
    "        return target, cross_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = random.randint(1, len(smi_list))\n",
    "\n",
    "def train_epoch(train_loader,test_loader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, tf):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad(), decoder_optimizer.zero_grad()\n",
    "        \n",
    "        e_all, e_last, self_attn = encoder(input)\n",
    "\n",
    "        # Teacher Forcing\n",
    "        if tf :\n",
    "          prediction, cross_attn = decoder(e_all, e_last, target)\n",
    "        else :\n",
    "          prediction, cross_attn = decoder(e_all, e_last)\n",
    "\n",
    "\n",
    "        loss = criterion(prediction, target)\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step(), decoder_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    encoder.eval(), decoder.eval()\n",
    "    \n",
    "\n",
    "\n",
    "    with torch.no_grad() :\n",
    "      for input, target in test_loader :\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        \n",
    "        e_all, e_last, self_attn = encoder(input)\n",
    "        prediction, cross_attn = decoder(e_all, e_last)\n",
    "\n",
    "        test_loss = criterion(prediction, target)\n",
    "        total_test_loss += test_loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader), total_test_loss / len(test_loader)\n",
    "\n",
    "\n",
    "def train(train_loader, test_loader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=1, visual_path= \"\", tf_rate = 1):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss_total = 0  \n",
    "    test_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    tf = True\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      if epoch > (tf_rate * n_epochs) :\n",
    "        tf = False\n",
    "      encoder.train()\n",
    "      decoder.train()\n",
    "\n",
    "      train_loss, test_loss = train_epoch(train_loader, test_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, tf)\n",
    "      train_loss_total += train_loss\n",
    "      test_loss_total += test_loss\n",
    "\n",
    "      for i in range(5) :\n",
    "         visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"cross\", path=f\"{visual_path}\", name=f\"R{i}-CROSS-E{epoch}\")\n",
    "         visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"self\", path=f\"{visual_path}\", name=f\"R{i}-SELF-E{epoch}\")\n",
    "\n",
    "      if epoch % print_every == 0:\n",
    "          train_loss_avg = train_loss_total / print_every\n",
    "          test_loss_avg = test_loss_total / print_every\n",
    "          train_loss_total = 0\n",
    "          test_loss_total = 0\n",
    "          print('%s (%d %d%%) /// Train loss: %.4f - Test loss: %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                      epoch, epoch / n_epochs * 100, train_loss_avg, test_loss_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_MODEL = 128\n",
    "NUM_BLOCK = 1\n",
    "NUM_HEAD = 4\n",
    "DROPOUT = 0.1\n",
    "FE = 1\n",
    "\n",
    "\n",
    "encoder = Encoder(dim_model=DIM_MODEL,\n",
    "                  num_block=NUM_BLOCK,\n",
    "                  num_head=NUM_HEAD,\n",
    "                  dropout=DROPOUT,\n",
    "                  fe = FE,\n",
    "                  len_dic=len(smi_dic)).to(device)\n",
    "\n",
    "decoder = Decoder(dim_model=DIM_MODEL,\n",
    "                  num_block=NUM_BLOCK,\n",
    "                  num_head=NUM_HEAD,\n",
    "                  dropout=DROPOUT,\n",
    "                  fe=FE,\n",
    "                  longest_coor=longest_coor,\n",
    "                  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\data_preprocess.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.x[idx], dtype = torch.long, device=device), torch.tensor(self.y[idx], device = device)\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:120: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + smi)\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:129: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + smi)\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:123: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + smi)\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:114: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 48m 28s) (1 2%) /// Train loss: 1.1702 - Test loss: 2.3717\n",
      "1m 51s (- 44m 29s) (2 4%) /// Train loss: 0.9020 - Test loss: 2.1432\n",
      "3m 5s (- 48m 22s) (3 6%) /// Train loss: 0.8862 - Test loss: 2.2062\n",
      "4m 19s (- 49m 44s) (4 8%) /// Train loss: 0.8814 - Test loss: 2.1180\n",
      "5m 31s (- 49m 40s) (5 10%) /// Train loss: 0.8777 - Test loss: 2.1893\n",
      "6m 47s (- 49m 45s) (6 12%) /// Train loss: 0.8697 - Test loss: 2.2766\n",
      "8m 1s (- 49m 17s) (7 14%) /// Train loss: 0.8666 - Test loss: 2.0731\n",
      "8m 45s (- 45m 59s) (8 16%) /// Train loss: 0.8552 - Test loss: 1.9457\n",
      "9m 24s (- 42m 49s) (9 18%) /// Train loss: 0.8515 - Test loss: 2.1646\n",
      "10m 4s (- 40m 18s) (10 20%) /// Train loss: 0.8493 - Test loss: 2.0381\n",
      "10m 43s (- 38m 2s) (11 22%) /// Train loss: 0.8479 - Test loss: 2.1048\n",
      "11m 26s (- 36m 13s) (12 24%) /// Train loss: 0.8430 - Test loss: 2.0829\n",
      "12m 6s (- 34m 29s) (13 26%) /// Train loss: 0.8422 - Test loss: 2.0254\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtf_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvisual_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 66\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, test_loader, encoder, decoder, n_epochs, learning_rate, print_every, visual_path, tf_rate)\u001b[0m\n\u001b[0;32m     63\u001b[0m encoder\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     64\u001b[0m decoder\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 66\u001b[0m train_loss, test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m train_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\n\u001b[0;32m     68\u001b[0m test_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m test_loss\n",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(train_loader, test_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, tf)\u001b[0m\n\u001b[0;32m     18\u001b[0m   prediction, cross_attn \u001b[38;5;241m=\u001b[39m decoder(e_all, e_last)\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(prediction, target)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mstep(), decoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_loader, test_loader, encoder, decoder,\n",
    "      n_epochs=50,\n",
    "      learning_rate=0.001,\n",
    "      tf_rate = 0.4,\n",
    "      visual_path=\"attention image\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:120: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + smi)\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:129: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + smi)\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:123: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + smi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:114: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5) :\n",
    "    r = random.randint(1, len(smi_list))\n",
    "    visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"cross\", path=f\"attention image\", name=f\"R{i}-CROSS-E{i}\")\n",
    "    visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"self\", path=f\"attention image\", name=f\"R{i}-SELF-E{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
