{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully extracted\n",
      "----------------------------------------\n",
      "Size: 4255\n",
      "Longest SMILES: 36\n",
      "Longest Coordinate: 22\n",
      "----------------------------------------\n",
      "smi_list (SMILES List):\n",
      "\t Cn1ncc(c1)B1OC(C(O1)(C)C)(C)CE\n",
      "smint_list (SMILES Integer List):\n",
      "\t [2, 3, 4, 3, 5, 5, 6, 5, 4, 7, 8, 4, 9, 2, 6, 2, 6, 9, 4, 7, 6, 2, 7, 2, 7, 6, 2, 7, 2, 1, 0, 0, 0, 0, 0, 0]\n",
      "coor_list (Coordinate List):\n",
      "\t [[4.8285, -1.004, 0.2024], [3.5776, -0.2572, 0.0479], [3.4435, 1.1346, 0.1047], [2.1893, 1.445, -0.0747], [1.4645, 0.2475, -0.2554], [2.3676, -0.7919, -0.1777], [-0.0805, 0.1225, -0.5047], [-1.0404, 1.1849, -0.5963], [-2.2048, 0.6858, 0.0949], [-2.0701, -0.8493, 0.0305], [-0.8409, -1.0789, -0.697], [-1.9777, -1.4359, 1.4405], [-3.2539, -1.4571, -0.7246], [-2.2055, 1.1603, 1.5494], [-3.4816, 1.1392, -0.6157]]\n",
      "np_coor_list (Normalized + Padded Coordinate List):\n",
      "\t tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [-1.2500,  0.7500, -0.1500],\n",
      "        [-1.3900,  2.1400, -0.1000],\n",
      "        [-2.6400,  2.4500, -0.2800],\n",
      "        [-3.3600,  1.2500, -0.4600],\n",
      "        [-2.4600,  0.2100, -0.3800],\n",
      "        [-4.9100,  1.1300, -0.7100],\n",
      "        [-5.8700,  2.1900, -0.8000],\n",
      "        [-7.0300,  1.6900, -0.1100],\n",
      "        [-6.9000,  0.1500, -0.1700],\n",
      "        [-5.6700, -0.0700, -0.9000],\n",
      "        [-6.8100, -0.4300,  1.2400],\n",
      "        [-8.0800, -0.4500, -0.9300],\n",
      "        [-7.0300,  2.1600,  1.3500],\n",
      "        [-8.3100,  2.1400, -0.8200],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "from utils.data_preprocess import train_loader, test_loader, smi_list, smint_list, smi_dic, coor_list, np_coor_list, longest_coor, longest_smi, device\n",
    "from utils.helper import visualize, timeSince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head) :\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.dim_model = dim_model\n",
    "        self.num_head = num_head\n",
    "        self.dim_head = dim_model // num_head\n",
    "\n",
    "        self.Q = nn.Linear(dim_model, dim_model)\n",
    "        self.K = nn.Linear(dim_model, dim_model)\n",
    "        self.V = nn.Linear(dim_model, dim_model)\n",
    "        print(self.dim_head)\n",
    "        self.out = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "    def forward(self, Q, K, V) :\n",
    "        B = Q.size(0) # Shape Q, K, V: (B, longest_smi, dim_model)\n",
    "\n",
    "        Q, K, V = self.Q(Q), self.K(K), self.V(V)\n",
    "\n",
    "        len_Q, len_K, len_V = Q.size(1), K.size(1), V.size(1)\n",
    "\n",
    "        Q = Q.reshape(B, self.num_head, len_Q, self.dim_head)\n",
    "        K = K.reshape(B, self.num_head, len_K, self.dim_head)\n",
    "        V = V.reshape(B, self.num_head, len_V, self.dim_head)\n",
    "        \n",
    "        K_T = K.transpose(2,3).contiguous()\n",
    "\n",
    "        attn_score = Q @ K_T\n",
    "\n",
    "        attn_score = attn_score / (self.dim_head ** 1/2)\n",
    "\n",
    "        attn_distribution = torch.softmax(attn_score, dim = -1)\n",
    "\n",
    "        attn = attn_distribution @ V\n",
    "\n",
    "        attn = attn.reshape(B, len_Q, self.num_head * self.dim_head)\n",
    "        \n",
    "        attn = self.out(attn)\n",
    "\n",
    "        return attn, attn_distribution\n",
    "\n",
    "class LSTM(nn.Module) :\n",
    "    def __init__(self, dim_model, longest_coor, num_head = 1, output_size = 3) :\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.longest_coor = longest_coor\n",
    "\n",
    "        self.cross_attn = SelfAttention(dim_model, num_head)\n",
    "\n",
    "        self.lstm = nn.LSTM(3 + dim_model, dim_model, batch_first=True)\n",
    "\n",
    "        self.out = nn.Linear(dim_model, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, e_all, e_last, target = None) :\n",
    "        B = e_all.size(0)\n",
    "\n",
    "        d_input = torch.zeros(B, 1, 3).to(device)\n",
    "\n",
    "        d_hidden = e_last\n",
    "\n",
    "        d_outputs, cross_attn = [], []\n",
    "\n",
    "        for i in range(self.longest_coor) :\n",
    "            d_output, d_hidden, step_attn = self.forward_step(d_input, d_hidden, e_all)\n",
    "\n",
    "            d_outputs.append(d_output), cross_attn.append(step_attn)\n",
    "\n",
    "            if target is not None :\n",
    "                d_input = target[:, i, :].unsqueeze(1)\n",
    "            else :\n",
    "                d_input = d_output\n",
    "\n",
    "        d_outputs = torch.cat(d_outputs, dim = 1)\n",
    "\n",
    "        cross_attn = torch.cat(cross_attn, dim = 2)\n",
    "        \n",
    "        return d_outputs, d_hidden, cross_attn\n",
    "\n",
    "\n",
    "    def forward_step(self, d_input, d_hidden, e_all) :\n",
    "        Q = d_hidden.permute(1,0,2)\n",
    "\n",
    "        d_input = self.dropout(d_input)\n",
    "\n",
    "        attn, attn_distribution = self.cross_attn(Q, e_all, e_all)\n",
    "\n",
    "        input_lstm = torch.cat((attn, d_input), dim = 2)\n",
    "\n",
    "        output, _ = self.lstm(input_lstm) # Recheck about 2nd param\n",
    "\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, d_hidden, attn_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head, fe, dropout) :\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attn = SelfAttention(dim_model,num_head)\n",
    "        self.norm1 = nn.LayerNorm(dim_model)\n",
    "        self.norm2 = nn.LayerNorm(dim_model)\n",
    "        self.lstm = nn.LSTM(input_size=dim_model, hidden_size=dim_model, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(dim_model, fe * dim_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fe * dim_model, dim_model)\n",
    "        )\n",
    "    def forward(self, Q, K, V) :\n",
    "\n",
    "        all_state, (last_state, _) = self.lstm(Q)\n",
    "\n",
    "        attn, attn_distribution = self.self_attn(all_state, all_state, all_state)\n",
    "\n",
    "        out = self.dropout(attn + all_state)\n",
    "\n",
    "        # out = self.dropout(self.norm1(attn + all_state))\n",
    "\n",
    "        # forward = self.feed_forward(x)\n",
    "\n",
    "        # out = self.dropout(self.norm2(forward + x))\n",
    "\n",
    "        return out, attn_distribution, last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "    def __init__(self, dim_model, num_block, num_head,\n",
    "                 len_dic, fe = 1, dropout = 0.1) :\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.dim_model = dim_model\n",
    "        self.embed = nn.Embedding(len_dic, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            EncoderBlock(dim_model, num_head, fe, dropout) for _ in range(num_block)\n",
    "        )\n",
    "\n",
    "    def forward(self, x) :\n",
    "        out = self.dropout(self.embed(x))\n",
    "\n",
    "        for block in self.encoder_blocks : \n",
    "            out, self_attn, last_state = block(out, out, out) \n",
    "        return out, last_state, self_attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head, longest_coor, fe, dropout) :\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.lstm = LSTM(dim_model, longest_coor, num_head)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim_model)\n",
    "        self.norm2 = nn.LayerNorm(3)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(3, fe * dim_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fe * dim_model, 3)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, e_all, e_last, target = None) :\n",
    "        output, _, cross_attn = self.lstm(e_all, e_last, target)\n",
    "        \n",
    "        # x = self.dropout(output)\n",
    "\n",
    "        # forward = self.feed_forward(x)\n",
    "\n",
    "        # out = self.dropout(self.norm2(forward + x))\n",
    "\n",
    "        return output, cross_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "    def __init__(self, dim_model,num_block, num_head, longest_coor, fe = 1, dropout = 0.1) :\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "            [DecoderBlock(dim_model, num_head,longest_coor, fe, dropout) for _ in range(num_block)]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, e_all, e_last, target = None) :\n",
    "        for block in self.decoder_blocks :\n",
    "            target, cross_attn = block(e_all, e_last, target)\n",
    "        \n",
    "        return target, cross_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader,test_loader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, tf):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad(), decoder_optimizer.zero_grad()\n",
    "        \n",
    "        e_all, e_last, self_attn = encoder(input)\n",
    "\n",
    "        # Teacher Forcing\n",
    "        if tf :\n",
    "          prediction, cross_attn = decoder(e_all, e_last, target)\n",
    "        else :\n",
    "          prediction, cross_attn = decoder(e_all, e_last)\n",
    "\n",
    "\n",
    "        loss = criterion(prediction, target)\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step(), decoder_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    encoder.eval(), decoder.eval()\n",
    "    \n",
    "\n",
    "\n",
    "    with torch.no_grad() :\n",
    "      for input, target in test_loader :\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        \n",
    "        e_all, e_last, self_attn = encoder(input)\n",
    "        prediction, cross_attn = decoder(e_all, e_last)\n",
    "\n",
    "        test_loss = criterion(prediction, target)\n",
    "        total_test_loss += test_loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader), total_test_loss / len(test_loader)\n",
    "\n",
    "\n",
    "def train(train_loader, test_loader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=1, visual_path= \"\", tf_rate = 1):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss_total = 0  \n",
    "    test_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    tf = True\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "      if epoch > (tf_rate * n_epochs) :\n",
    "        tf = False\n",
    "      encoder.train()\n",
    "      decoder.train()\n",
    "\n",
    "      train_loss, test_loss = train_epoch(train_loader, test_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, tf)\n",
    "      train_loss_total += train_loss\n",
    "      test_loss_total += test_loss\n",
    "\n",
    "      for i in range(5) :\n",
    "         r = random.randint(1, len(smi_list))\n",
    "         visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"cross\", path=f\"{visual_path}\", name=f\"R{i}-CROSS-E{epoch}\")\n",
    "         visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"self\", path=f\"{visual_path}\", name=f\"R{i}-SELF-E{epoch}\")\n",
    "\n",
    "      if epoch % print_every == 0:\n",
    "          train_loss_avg = train_loss_total / print_every\n",
    "          test_loss_avg = test_loss_total / print_every\n",
    "          train_loss_total = 0\n",
    "          test_loss_total = 0\n",
    "          print('%s (%d %d%%) /// Train loss: %.4f - Test loss: %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                      epoch, epoch / n_epochs * 100, train_loss_avg, test_loss_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "DIM_MODEL = 128\n",
    "NUM_BLOCK = 1\n",
    "NUM_HEAD = 4\n",
    "DROPOUT = 0.1\n",
    "FE = 1\n",
    "\n",
    "\n",
    "encoder = Encoder(dim_model=DIM_MODEL,\n",
    "                  num_block=NUM_BLOCK,\n",
    "                  num_head=NUM_HEAD,\n",
    "                  dropout=DROPOUT,\n",
    "                  fe = FE,\n",
    "                  len_dic=len(smi_dic)).to(device)\n",
    "\n",
    "decoder = Decoder(dim_model=DIM_MODEL,\n",
    "                  num_block=NUM_BLOCK,\n",
    "                  num_head=NUM_HEAD,\n",
    "                  dropout=DROPOUT,\n",
    "                  fe=FE,\n",
    "                  longest_coor=longest_coor,\n",
    "                  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\data_preprocess.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.x[idx], dtype = torch.long, device=device), torch.tensor(self.y[idx], device = device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:120: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + smi)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/H1-R0-CROSS-E1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 72\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, test_loader, encoder, decoder, n_epochs, learning_rate, print_every, visual_path, tf_rate)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m) :\n\u001b[0;32m     71\u001b[0m    r \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(smi_list))\n\u001b[1;32m---> 72\u001b[0m    \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmi_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmi_dic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongest_smi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcross\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvisual_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-CROSS-E\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m    visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisual_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-SELF-E\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:161\u001b[0m, in \u001b[0;36mvisualize\u001b[1;34m(encoder, decoder, smi, smi_dic, longest_smi, mode, path, name)\u001b[0m\n\u001b[0;32m    157\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m self_attn[:smi_len, :smi_len]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_head) :\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mplot_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:128\u001b[0m, in \u001b[0;36mplot_attn\u001b[1;34m(matrix, smi, mode, path, name)\u001b[0m\n\u001b[0;32m    125\u001b[0m ax\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_major_locator(ticker\u001b[38;5;241m.\u001b[39mMultipleLocator(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    126\u001b[0m ax\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mset_major_locator(ticker\u001b[38;5;241m.\u001b[39mMultipleLocator(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 128\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3374\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3375\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[0;32m   3376\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m-> 3378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 458\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2410\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2408\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2410\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2413\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/H1-R0-CROSS-E1.png'"
     ]
    }
   ],
   "source": [
    "train(train_loader, test_loader, encoder, decoder, n_epochs=50, learning_rate=0.001, tf_rate = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:120: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + smi)\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:129: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + smi)\n",
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:123: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + smi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\OneDrive\\Desktop\\moffitt\\transformer-smi2coor\\utils\\helper.py:114: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n",
      "cross attn: (4, 22, 36)\n",
      "self attn: (4, 36, 36)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5) :\n",
    "    r = random.randint(1, len(smi_list))\n",
    "    visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"cross\", path=f\"attention image\", name=f\"R{i}-CROSS-E{i}\")\n",
    "    visualize(encoder, decoder, smi_list[r], smi_dic, longest_smi, mode=\"self\", path=f\"attention image\", name=f\"R{i}-SELF-E{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
